{
  "id": "request-batch",
  "name": "Request Batch",
  "category": "Distributed Systems",
  "description": "A pattern for grouping multiple requests together to reduce network overhead and improve efficiency",
  "when_to_use": "High-frequency requests, network optimization, bulk operations",
  "benefits": "Reduced network overhead, improved throughput, better resource utilization",
  "drawbacks": "Increased latency for individual requests, complexity in request ordering",
  "use_cases": "API calls, database operations, message queues, logging",
  "complexity": "Medium",
  "tags": ["distributed-systems", "performance", "network-optimization", "batch-processing"],
  "examples": {
    "typescript": {
      "language": "typescript",
      "code": "class RequestBatch {\n  private requests: BatchRequest[] = [];\n  private batchSize: number;\n  private timeoutMs: number;\n  private timer: NodeJS.Timeout | null = null;\n  \n  constructor(batchSize: number = 10, timeoutMs: number = 100) {\n    this.batchSize = batchSize;\n    this.timeoutMs = timeoutMs;\n  }\n  \n  async add<T>(request: BatchRequest): Promise<T> {\n    return new Promise<T>((resolve, reject) => {\n      this.requests.push({\n        ...request,\n        resolve,\n        reject\n      });\n      \n      this.scheduleFlush();\n    });\n  }\n  \n  private scheduleFlush() {\n    if (this.requests.length >= this.batchSize) {\n      this.flush();\n    } else if (!this.timer) {\n      this.timer = setTimeout(() => this.flush(), this.timeoutMs);\n    }\n  }\n  \n  private async flush() {\n    if (this.timer) {\n      clearTimeout(this.timer);\n      this.timer = null;\n    }\n    \n    if (this.requests.length === 0) return;\n    \n    const batch = this.requests.splice(0);\n    \n    try {\n      const results = await this.processBatch(batch);\n      batch.forEach((request, index) => {\n        request.resolve(results[index]);\n      });\n    } catch (error) {\n      batch.forEach(request => {\n        request.reject(error);\n      });\n    }\n  }\n  \n  private async processBatch(batch: BatchRequest[]): Promise<any[]> {\n    // Group by endpoint for efficiency\n    const endpointGroups = new Map<string, BatchRequest[]>();\n    \n    for (const request of batch) {\n      const key = `${request.method}:${request.url}`;\n      if (!endpointGroups.has(key)) {\n        endpointGroups.set(key, []);\n      }\n      endpointGroups.get(key)!.push(request);\n    }\n    \n    const results: any[] = [];\n    \n    for (const [endpoint, requests] of endpointGroups) {\n      const [method, url] = endpoint.split(':');\n      \n      if (method === 'GET' && requests.length > 1) {\n        // Batch GET requests if supported by the API\n        const batchedResult = await this.batchGet(url, requests);\n        results.push(...batchedResult);\n      } else {\n        // Process individually\n        const individualResults = await Promise.all(\n          requests.map(req => this.makeRequest(req))\n        );\n        results.push(...individualResults);\n      }\n    }\n    \n    return results;\n  }\n  \n  private async makeRequest(request: BatchRequest): Promise<any> {\n    const response = await fetch(request.url, {\n      method: request.method,\n      headers: request.headers,\n      body: request.body\n    });\n    \n    if (!response.ok) {\n      throw new Error(`HTTP ${response.status}`);\n    }\n    \n    return response.json();\n  }\n  \n  private async batchGet(baseUrl: string, requests: BatchRequest[]): Promise<any[]> {\n    // Example: if API supports batch endpoints\n    const ids = requests.map(req => this.extractIdFromUrl(req.url));\n    const batchUrl = `${baseUrl}?ids=${ids.join(',')}`;\n    \n    const response = await fetch(batchUrl);\n    const data = await response.json();\n    \n    // Map back to individual request order\n    return ids.map(id => data[id]);\n  }\n  \n  private extractIdFromUrl(url: string): string {\n    // Simple ID extraction - would need to be more sophisticated\n    const match = url.match(/\\/(\\d+)$/);\n    return match ? match[1] : '';\n  }\n}\n\ninterface BatchRequest {\n  url: string;\n  method: string;\n  headers?: Record<string, string>;\n  body?: string;\n  resolve: (value: any) => void;\n  reject: (error: any) => void;\n}\n\n// Usage example\nconst batchProcessor = new RequestBatch(5, 50);\n\n// Add multiple requests\nPromise.all([\n  batchProcessor.add({ url: '/api/users/1', method: 'GET' }),\n  batchProcessor.add({ url: '/api/users/2', method: 'GET' }),\n  batchProcessor.add({ url: '/api/users/3', method: 'GET' }),\n  batchProcessor.add({ \n    url: '/api/users', \n    method: 'POST', \n    body: JSON.stringify({ name: 'John' }),\n    headers: { 'Content-Type': 'application/json' }\n  })\n]).then(results => {\n  console.log('Batch results:', results);\n});\n\n// Database batch operations\nclass DatabaseBatch {\n  private operations: DatabaseOperation[] = [];\n  private batchSize: number;\n  \n  constructor(batchSize: number = 100) {\n    this.batchSize = batchSize;\n  }\n  \n  add(operation: DatabaseOperation) {\n    this.operations.push(operation);\n    \n    if (this.operations.length >= this.batchSize) {\n      this.flush();\n    }\n  }\n  \n  flush() {\n    if (this.operations.length === 0) return;\n    \n    const batch = this.operations.splice(0);\n    this.executeBatch(batch);\n  }\n  \n  private async executeBatch(operations: DatabaseOperation[]) {\n    // Execute as transaction\n    const transaction = await this.beginTransaction();\n    \n    try {\n      for (const op of operations) {\n        await this.executeOperation(transaction, op);\n      }\n      await transaction.commit();\n    } catch (error) {\n      await transaction.rollback();\n      throw error;\n    }\n  }\n  \n  private async beginTransaction() {\n    // Database-specific transaction logic\n    return {};\n  }\n  \n  private async executeOperation(transaction: any, operation: DatabaseOperation) {\n    // Execute individual operation within transaction\n  }\n}\n\ninterface DatabaseOperation {\n  type: 'insert' | 'update' | 'delete';\n  table: string;\n  data: any;\n}"
    }
  }
}
